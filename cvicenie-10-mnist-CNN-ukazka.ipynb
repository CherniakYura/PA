{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spustite si server pre deep learning, ktory ma nainstalovany tensorflow a keras \n",
    "# (File - Hub Control Panel ... Stop server, nasledne start ... a vyberte Jupyter Notbeook Deep Learning Stack )\n",
    "\n",
    "# naimportujeme si potrebné knižnice a typy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import utils\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nacitame si data dostupne priamo v kerase - MNIST data, ide o rucne pisane cislice\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jeden konkretny priklad cislice \n",
    "plt.imshow(trainX[25], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre neuronove siete sa odporuca vstupy normalizovat - potrebujeme hodnoty pixelov (jas) normalizovat tak aby boli mensie ako 1, v tomto pripade teda na interval [0,1]\n",
    "# kedze hodnoty jasu su od 0 do 255, zmenime typ na float a predelime ich /255\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aj ked sa skala zmenila, obrazok vykresleny cez plt.imshow vidime ze vyzera rovnako, takze sme to zjavne neurobil chybu pri skalovani\n",
    "plt.imshow(trainX[25], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vytvorenie modelu ... sekvencne, povedzme ze urobime jednoduchu siet ktora pozostava z konvolucnej casti a doprednej casti siete\n",
    "# akakolvek vrstva je prva, musi definovat input_shape vstupov, ktore sa pre nu budu pouzivat - u nas (28,28,1) pre obrazky 28*28 v 1 \"farbe\" (urovne jasu)\n",
    "# ak chceme pouzit konvolucne vrstvy a pooling vrstvy, dame ich pred flatten vrstvu\n",
    "# mozeme zakomponovat aj regularizaciu, napr. dropout\n",
    "# Dense vrstvy su plne prepojene vrstvy pouzivane na klasifikaciu - representuju feed forward siet, postupne zmensujeme pocet neuronov vo vrstve a tak ucime kompaktnejsiu reprezentaciu\n",
    "# posledna vrstva ma tolko neuronov, kolko je binarnych vystupov pre reprezentaciu toho, ktora cislica to je - cize 10 neuronov v nasom pripade, typ aktivacie softmax \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# pomocou summary si vieme zobrazit strukturu modelu\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skompilujeme model ... ide o akesi nastavenie celeho mechanizmu ucenia siete (samotne ucenie bude ako tradicne pomocou fit)\n",
    "# optimizer je typ optimalizacneho algoritmu, pouzijeme oblubeny algoritmus Adam, s default nastaveniami (preto prazdna zatvorka pri volani)\n",
    "# pre chybovu funkciu loss sa pre viac tried pozuiva categorical_crossentropy, ako metriku na urcenie kvality klasifikacie pouzijeme accuracy\n",
    "# v pripade binarnej klasifikacie sa pouziva vystupna vrstva sigmoid (posledna Dense vrstva) a loss funkcia sa potom tu pozuije binary_crossentropy\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre skompilovany model mozeme nasledne spustit proces ucenia pomocou fit\n",
    "# mozeme pouzit validation_split a definovat kolko s trenovacej mnoziny bude pouzite samostatne ako validacna mnozina\n",
    "# pripadne mozeme nastavit validacnu mnozinu samostatne (validation_data), alebo ju vobec nepouzit\n",
    "# tiez musime cielove hodnoty trenovacej sady (trainY) pre potreby trenovania neuronovej siete zakodovat ako binarny vektor, kedze ich musime mapovat na softmax vrstvu s 10 neuronmi\n",
    "# mozeme pouzit napr. utils funkciu kniznice keras to_categorical, vysledkom je napr. cislica 3 je zakodovane takto [0,0,0,1,0,0,0,0,0,0], cislica 7 zase [0,0,0,0,0,0,0,1,0,0] atd.\n",
    "# dosiahneme to pouzitim utils.to_categorical(trainY, 10)\n",
    "f = model.fit(trainX, utils.to_categorical(trainY, 10), epochs=2, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skusme predikciu konkretnej cislice, napr. index 32 (cize podmnozinu testX od 32 po 33 bez 33 - python)\n",
    "# dostaneme aktivacne hodnoty na jednotlivych neuronoch vystupnej vrstvy - je to binarne zakodovana cislica, jedna hodnota je vyrazne vacsia, zodpoveda neuronu pre danu cislicu\n",
    "some_prediction = model.predict(testX[32:33])\n",
    "some_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ako vyzeraju rozdiely v hodnotach predikcie si mozeme pozriet aj na grafe, ukaze nam poziciu najvacsej hodnoty\n",
    "# podla toho kde je vidime, ze index pozicie je 3 -> cize cislica je 3\n",
    "plt.bar(np.arange(10), some_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na porovnanie vykreslime obrazok daneho testovacieho prikladu, vidime ze skutocne ide o 3, predikcia bola uspesna\n",
    "plt.imshow(testX[32], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# vytvorime si predikcie na celej testX a prerobime ich na konkretnu hodnotu kategorie (cislicu) tak ze zistime argument (index) maximalnej hodnoty v ramci predikovaneho bin.vektora\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(testX)\n\u001b[1;32m      3\u001b[0m y_predicted_categories \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_predictions, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# vytvorime si predikcie na celej testX a prerobime ich na konkretnu hodnotu kategorie (cislicu) tak ze zistime argument (index) maximalnej hodnoty v ramci predikovaneho bin.vektora\n",
    "y_predictions = model.predict(testX)\n",
    "y_predicted_categories = np.argmax(y_predictions, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mozeme si vypisat predikovane hodnoty kategorii pre jednotlive prvky testX \n",
    "\n",
    "y_predicted_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vidime ze pre 32 zaznam to opat sedi, hodnota je 3\n",
    "y_predicted_categories[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vytvorime confusion matrix na testovacej mnozine porovnanim predikovanych (y_predicted_ctaegories) a skutocnych hodnot y (testY) prikladov v testovacej mnozine\n",
    "pd.crosstab(testY, y_predicted_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mozeme vypisat aj klasifikacny report \n",
    "print(classification_report(testY, y_predicted_categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
